{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsheets\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the credentials from the JSON file (replace with the path to your file)\n",
    "sf_path = r'inductive-gift-355101-48518c54d576.json'\n",
    "gc = pygsheets.authorize(service_account_file=sf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_gsheet(service_file_path, spreadsheet_id, sheet_name):\n",
    "    gc = pygsheets.authorize(service_file=service_file_path)\n",
    "    sh = gc.open_by_key(spreadsheet_id)\n",
    "    wks = sh.worksheet_by_title(sheet_name)\n",
    "    df = wks.get_as_df(\n",
    "        numerize=False, value_render='UNFORMATTED_VALUE', empty_value=None)\n",
    "    df = df.replace(to_replace='', value=None)\n",
    "\n",
    "    return df\n",
    "\n",
    "# %%\n",
    "# lay du lieu tu googhesheet ma khong co du lieu so\n",
    "\n",
    "\n",
    "def get_df_from_gsheet(service_file_path, spreadsheet_id, sheet_name, start=None):\n",
    "    gc = pygsheets.authorize(service_file=service_file_path)\n",
    "    sh = gc.open_by_key(spreadsheet_id)\n",
    "    wks = sh.worksheet_by_title(sheet_name)\n",
    "    df = wks.get_as_df(start, numerize=False, empty_value=None)\n",
    "    df = df.replace(to_replace='', value=None)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sheet_name, start):\n",
    "    spreadsheet_id = '1Bmm9GGP3QE5k_T8eODN3Hrh8ICzMgAazYkw0gWNRZDs'\n",
    "\n",
    "    gc = pygsheets.authorize(service_file=sf_path)\n",
    "    sh = gc.open_by_key(spreadsheet_id)\n",
    "    wks = sh.worksheet_by_title(sheet_name)\n",
    "    df = wks.get_as_df(start, numerize=False, value_render='UNFORMATTED_VALUE', empty_value=None)\n",
    "    df = df.replace(to_replace='', value=None)\n",
    "    # df.drop_duplicates(inplace=True)\n",
    "\n",
    "    df2 = df.transpose()\n",
    "    df2.iloc[:,1] = df2.iloc[:,1].ffill()\n",
    "    df3 = df2.transpose()\n",
    "    # Combine the two lists\n",
    "    combined_list = [f\"{a}|{b}\" for a, b in zip(df3.iloc[1].to_list(), df3.iloc[2].to_list())]\n",
    "    df3.columns = combined_list\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_daily(df3, sheet_name):\n",
    "    df_daily = df3.iloc[10:,:]\n",
    "    df_daily2 = df_daily.melt(id_vars='None|None')\n",
    "    df_daily2[['user', 'criteria']] =df_daily2['variable'].str.split('|', expand=True)\n",
    "    df_daily2.rename(columns={'None|None':'report_date'}, inplace=True)\n",
    "    df_daily2.drop(columns='variable', inplace=True)\n",
    "    df_daily2.dropna(subset='value', inplace=True)\n",
    "    df_daily3 = df_daily2.query(\"value!=0\").pivot(columns='criteria', index=['user', 'report_date'], values='value').reset_index()\n",
    "    df_daily3['report_date'] = df_daily3['report_date'].astype('str') + '/' + sheet_name\n",
    "    df_daily3['report_date'] = pd.to_datetime(df_daily3['report_date'], format='%d/%m/%Y')\n",
    "    # df_daily3.to_parquet(rf\".\\data\\daily\\{str(sheet_name).replace('/', '-')}.parquet\", index=False )\n",
    "    return df_daily3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_target(df3, sheet_name):\n",
    "    df_target = df3.iloc[3:10]\n",
    "    df_target.rename(columns={\"None|None\":\"item\"}, inplace=True)\n",
    "    df_target.query(\"item.isin(['Target', 'Daily'])\", inplace=True)\n",
    "\n",
    "    df_target2 = df_target.melt(id_vars='item')\n",
    "    df_target2[['user', 'criteria']] =df_target2['variable'].str.split('|', expand=True)\n",
    "    # df_target2.rename(columns={'item':'report_date'}, inplace=True)\n",
    "    df_target2.drop(columns='variable', inplace=True)\n",
    "    df_target2.dropna(subset='value', inplace=True)\n",
    "\n",
    "    df_target2.drop_duplicates(subset=['item', 'user'], inplace=True)\n",
    "    df_target3 = df_target2.query(\"value!=0\").pivot(columns='item', index=['user'], values='value').reset_index()\n",
    "\n",
    "    df_target3['report_month'] = '01/' + sheet_name\n",
    "    df_target3['report_month'] = pd.to_datetime(df_target3['report_month'], format='%d/%m/%Y')\n",
    "    # df_target3.to_parquet(rf\".\\data\\target\\{str(sheet_name).replace('/', '-')}.parquet\", index=False )\n",
    "    return df_target3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/2024\n"
     ]
    }
   ],
   "source": [
    "sheets = [\n",
    "        '9/2024',\n",
    "        # '8/2024',\n",
    "        # '7/2024',\n",
    "        # '6/2024',\n",
    "        # '5/2024',\n",
    "        # '4/2024',\n",
    "        # '3/2024',\n",
    "        # '2/2024',\n",
    "        # '1/2024',\n",
    "        # '12/2023',\n",
    "        # '11/2023',\n",
    "        # '10/2023',\n",
    "        # '9/2023',\n",
    "        # '8/2023',\n",
    "        # '7/2023',\n",
    "        # '6/2023',\n",
    "        # '5/2023',\n",
    "        # '4/2023',\n",
    "        # '3/2023',\n",
    "        # '2/2023',\n",
    "        # '1/2023',\n",
    "]\n",
    "for sheet_name in sheets:\n",
    "    df3 = get_data(sheet_name=sheet_name, start='A1')\n",
    "    df_daily = extract_daily(df3, sheet_name)\n",
    "    df_target = extract_target(df3, sheet_name)\n",
    "    # Get start of month and number of days in the month\n",
    "    start_of_month = df_target.loc[0,'report_month']\n",
    "    num_days = start_of_month.days_in_month\n",
    "\n",
    "    # Create a date range for each day of the month\n",
    "    date_range = pd.date_range(start_of_month, periods=num_days, freq='D')\n",
    "    df_target['report_date'] = [date_range]*len(df_target)\n",
    "    df_target = df_target.explode('report_date')\n",
    "    df_target['report_day'] = df_target['report_date'].dt.day\n",
    "    df_target['no_of_day'] = num_days\n",
    "    df_target['Daily'] = df_target['Daily'].astype(int)\n",
    "\n",
    "    df_target['Target'] = df_target['Target'].astype(int)\n",
    "    df_target['daily_target_norm'] =  df_target['Target']/df_target[\"no_of_day\"]\n",
    "    df_target['mtd_target_norm'] = df_target['daily_target_norm'] * df_target['report_day']\n",
    "    dta = df_target.merge(df_daily, how='left', on=['user','report_date'])\n",
    "    dta['Total'] = dta['Total'].fillna(0)\n",
    "    dta['Total'] = pd.to_numeric(dta['Total'], errors='coerce')\n",
    "    dta['mtd_actual'] = dta.sort_values(by=['user', 'report_date']).groupby(['user'])['Total'].cumsum()\n",
    "    # danh dau ngay dai daily target\n",
    "    dta['flg_daily']  = 0\n",
    "    flt = dta['Total'] >= dta['Daily']\n",
    "    dta.loc[flt, 'flg_daily'] = 1\n",
    "\n",
    "    # danh dau ngay co tap luyen\n",
    "    dta['flg_workout'] = 0\n",
    "    flt = dta['Total'] >0\n",
    "    dta.loc[flt, 'flg_workout'] = 1\n",
    "\n",
    "\n",
    "    for col in ['Burpee', 'Core','Pushup', 'Run', 'Squat','flg_daily', 'flg_workout']:\n",
    "        try:\n",
    "            dta[col] = pd.to_numeric(dta[col], errors='coerce')\n",
    "            dta[col] = dta[col].fillna(0)\n",
    "            new_col = 'mtd_'+col\n",
    "            dta[new_col] = dta.sort_values(by=['user', 'report_date']).groupby(['user'])[col].cumsum()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    # tinh toan accumulate\n",
    "    dta.to_parquet(rf\".\\data\\daily\\dta_{str(sheet_name).replace('/', '-')}.parquet\", index=False )\n",
    "    print(sheet_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
